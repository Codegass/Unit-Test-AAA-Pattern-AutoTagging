testClassName,testMethodName,potentialTargetQualifiedName,AAA
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"NEW org.apache.druid.indexer.partitions.HashedPartitionsSpec(Integer, Integer, List<String>)",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,     TEST org.apache.druid.indexing.common.task.batch.parallel.AbstractMultiPhaseParallelIndexingTest.isUseInputFormatApi(),0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"               NEW org.apache.druid.segment.indexing.granularity.UniformGranularitySpec(Granularity, Granularity, List<Interval>)",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                    NEW org.apache.druid.data.input.MaxSizeSplitHintSpec(Long),0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"                    NEW org.apache.druid.indexing.common.task.batch.parallel.ParallelIndexTuningConfig(Integer, Integer, Integer, Long, Long, Integer, SplitHintSpec, PartitionsSpec, IndexSpec, IndexSpec, Integer, Boolean, Boolean, Long, SegmentWriteOutMediumFactory, Integer, Integer, Integer, Long, Duration, Integer, Integer, Integer, Boolean, Integer, Integer)",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"               NEW org.apache.druid.data.input.impl.LocalInputSource(File, String)",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"               NEW org.apache.druid.indexing.common.task.batch.parallel.ParallelIndexIOConfig(FirehoseFactory, InputSource, InputFormat, Boolean)",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"               NEW org.apache.druid.segment.indexing.DataSchema(String, TimestampSpec, DimensionsSpec, AggregatorFactory[], GranularitySpec, TransformSpec)",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"               NEW org.apache.druid.indexing.common.task.batch.parallel.ParallelIndexIngestionSpec(DataSchema, ParallelIndexIOConfig, ParallelIndexTuningConfig)",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"               NEW org.apache.druid.query.aggregation.LongSumAggregatorFactory(String, String)",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"               NEW org.apache.druid.segment.realtime.firehose.LocalFirehoseFactory(File, String, StringInputRowParser)",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"               NEW org.apache.druid.indexing.common.task.batch.parallel.ParallelIndexIOConfig(FirehoseFactory, Boolean)",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,               TEST org.apache.druid.indexing.common.task.IngestionTestBase.getObjectMapper(),0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"               NEW org.apache.druid.data.input.impl.StringInputRowParser(ParseSpec, String)",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,               TEST org.apache.druid.indexing.common.task.IngestionTestBase.getObjectMapper(),0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"               NEW org.apache.druid.segment.indexing.DataSchema(String, Map<String,Object>, AggregatorFactory[], GranularitySpec, TransformSpec, ObjectMapper)",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"               NEW org.apache.druid.indexing.common.task.batch.parallel.ParallelIndexIngestionSpec(DataSchema, ParallelIndexIOConfig, ParallelIndexTuningConfig)",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"               NEW org.apache.druid.query.aggregation.LongSumAggregatorFactory(String, String)",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"               NEW org.apache.druid.indexing.common.task.batch.parallel.ParallelIndexSupervisorTask(String, String, TaskResource, ParallelIndexIngestionSpec, Map<String,Object>, IndexingServiceClient, ChatHandlerProvider, AuthorizerMapper, RowIngestionMetersFactory, AppenderatorsManager)",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"               org.apache.druid.indexing.common.task.Task.addToContext(String, Object)",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,               TEST org.apache.druid.indexing.common.task.batch.parallel.AbstractParallelIndexSupervisorTaskTest.getIndexingServiceClient(),0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"                         org.apache.druid.indexing.common.task.Task.getContextValue(String, Boolean)",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"                         org.apache.druid.java.util.common.logger.Logger.error(Throwable, String, Object[])",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                              NEW org.apache.druid.indexing.common.task.batch.parallel.AbstractParallelIndexSupervisorTaskTest.TaskContainer(Task),0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                              org.apache.druid.indexing.common.task.Task.getId(),0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                              org.apache.druid.indexing.common.task.Task.getId(),0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"                              NEW org.apache.druid.java.util.common.ISE(String, Object[])",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                                   org.apache.druid.indexing.overlord.TaskLockbox.add(Task),0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                                   org.apache.druid.indexing.common.task.Task.getId(),0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                                   org.apache.druid.indexer.TaskStatus.running(String),0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"                                   org.apache.druid.indexing.overlord.TaskStorage.insert(Task, TaskStatus)",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                                   NEW org.apache.druid.indexing.common.task.IngestionTestBase.TestLocalTaskActionClient(Task),0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"                                   NEW org.apache.druid.server.DruidNode(String, String, boolean, Integer, Integer, boolean, boolean)",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                                   NEW anonymous(),0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                                   NEW org.apache.druid.segment.loading.LocalDataSegmentPusher(LocalDataSegmentPusherConfig),0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                                   NEW org.apache.druid.segment.loading.NoopDataSegmentKiller(),0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                                        org.apache.druid.indexing.common.SegmentLoaderFactory.manufacturate(File),0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                                   org.apache.druid.indexing.common.task.Task.getId(),0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                                        TEST org.apache.druid.indexing.common.TestUtils.getTestIndexIO(),0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                                        TEST org.apache.druid.indexing.common.TestUtils.getTestIndexMergerV9(),0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                                   NEW org.apache.druid.indexing.common.task.NoopTestTaskReportFileWriter(),0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"                                   NEW org.apache.druid.indexing.common.TaskToolbox(TaskConfig, DruidNode, TaskActionClient, ServiceEmitter, DataSegmentPusher, DataSegmentKiller, DataSegmentMover, DataSegmentArchiver, DataSegmentAnnouncer, DataSegmentServerAnnouncer, SegmentHandoffNotifierFactory, Provider<QueryRunnerFactoryConglomerate>, ExecutorService, JoinableFactory, Provider<MonitorScheduler>, SegmentLoader, ObjectMapper, File, IndexIO, Cache, CacheConfig, CachePopulatorStats, IndexMergerV9, DruidNodeAnnouncer, DruidNode, LookupNodeService, DataNodeService, TaskReportFileWriter, IntermediaryDataManager)",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                              TEST org.apache.druid.indexing.common.task.batch.parallel.AbstractParallelIndexSupervisorTaskTest.TaskContainer.setActionClient(TestLocalTaskActionClient),0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                              org.apache.druid.indexing.common.TaskToolbox.getTaskActionClient(),0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                              org.apache.druid.indexing.common.task.Task.isReady(TaskActionClient),0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                              org.apache.druid.indexing.common.task.Task.run(TaskToolbox),1
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                              TEST org.apache.druid.indexing.common.task.IngestionTestBase.getTaskStorage(),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                              org.apache.druid.indexing.common.task.Task.getId(),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                              org.apache.druid.indexer.TaskStatus.failure(String),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                              org.apache.druid.indexing.overlord.TaskStorage.setStatus(TaskStatus),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                              org.apache.druid.indexing.common.task.Task.getId(),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"                              NEW org.apache.druid.java.util.common.ISE(String, Object[])",2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                              TEST org.apache.druid.indexing.common.task.IngestionTestBase.getTaskStorage(),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                              org.apache.druid.indexing.common.task.Task.getId(),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"                              org.apache.druid.indexer.TaskStatus.failure(String, String)",2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                              org.apache.druid.indexing.overlord.TaskStorage.setStatus(TaskStatus),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                              TEST org.apache.druid.indexing.common.task.batch.parallel.AbstractParallelIndexSupervisorTaskTest.TaskContainer.setStatusFuture(Future<TaskStatus>),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                                   org.apache.druid.indexing.overlord.TaskLockbox.remove(Task),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,               org.apache.druid.indexer.TaskStatus.getStatusCode(),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"               ASSERT org.junit.Assert.assertEquals(Object, Object)",2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,               TEST org.apache.druid.indexing.common.task.batch.parallel.AbstractParallelIndexSupervisorTaskTest.getIndexingServiceClient(),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                    org.apache.druid.indexing.common.task.Task.getId(),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,                         TEST org.apache.druid.indexing.common.task.IngestionTestBase.TestLocalTaskActionClient.getPublishedSegments(),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"     TEST org.apache.druid.indexing.common.task.batch.parallel.AbstractMultiPhaseParallelIndexingTest.runTestTask(TimestampSpec, DimensionsSpec, InputFormat, ParseSpec, Interval, File, String, PartitionsSpec, int, TaskState, boolean)",2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"NEW org.apache.druid.indexer.partitions.DynamicPartitionsSpec(Integer, Long)",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"TEST org.apache.druid.indexing.common.task.batch.parallel.HashPartitionMultiPhaseParallelIndexingTest.runTestTask(PartitionsSpec, TaskState, boolean)",1
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"NEW org.apache.druid.indexer.partitions.DynamicPartitionsSpec(Integer, Long)",0
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"TEST org.apache.druid.indexing.common.task.batch.parallel.HashPartitionMultiPhaseParallelIndexingTest.runTestTask(PartitionsSpec, TaskState, boolean)",1
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,org.apache.druid.timeline.DataSegment.getInterval(),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,org.apache.druid.timeline.DataSegment.getShardSpec(),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,org.apache.druid.timeline.DataSegment.getShardSpec(),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,org.apache.druid.timeline.DataSegment.getShardSpec(),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,org.apache.druid.timeline.DataSegment.getInterval(),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,org.apache.druid.timeline.DataSegment.getInterval(),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"ASSERT org.junit.Assert.assertEquals(Object, Object)",2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,org.apache.druid.timeline.DataSegment.getVersion(),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,org.apache.druid.timeline.DataSegment.getVersion(),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"ASSERT org.junit.Assert.assertEquals(Object, Object)",2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,org.apache.druid.timeline.DataSegment.getShardSpec(),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,org.apache.druid.timeline.partition.NumberedShardSpec.getNumCorePartitions(),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,org.apache.druid.timeline.partition.NumberedShardSpec.getNumCorePartitions(),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,"ASSERT org.junit.Assert.assertEquals(long, long)",2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,ASSERT org.junit.Assert.assertTrue(boolean),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,org.apache.druid.timeline.partition.NumberedShardSpec.getPartitionNum(),2
HashPartitionMultiPhaseParallelIndexingTest,testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend,org.apache.druid.timeline.partition.NumberedShardSpec.getPartitionNum(),2
