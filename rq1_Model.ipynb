{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ1 Which Model is the Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Merge Finished.\n"
     ]
    }
   ],
   "source": [
    "from DataClean import Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data_edit = Data('./data/','edit distance', 'basic', tag=True, data_structure='clean').df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'> 12386\n",
      "<class 'int'> 5937\n",
      "<class 'int'> 1024\n"
     ]
    }
   ],
   "source": [
    "a = data_edit['AAA'].value_counts()\n",
    "for i, j in a.items():\n",
    "    print(type(i), j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_twist(df):\n",
    "    df = df.fillna(0)\n",
    "    for i in range(df.shape[0]):\n",
    "        if df.loc[i,'AAA'] == '1,2':\n",
    "            df.loc[i,'AAA'] = 2\n",
    "        elif df.loc[i,'AAA'] == '0,1':\n",
    "            df.loc[i,'AAA'] = 0\n",
    "        elif df.loc[i,'AAA'] == '0,2':\n",
    "            df.loc[i,'AAA'] = 0\n",
    "        elif df.loc[i,'AAA'] == '0,1,2':\n",
    "            df.loc[i,'AAA'] = 0\n",
    "        elif df.loc[i,'AAA'] =='/':\n",
    "            df.loc[i,'AAA'] = 0\n",
    "        elif df.loc[i,'AAA'] == np.nan:\n",
    "            df.loc[i,'AAA'] = 0\n",
    "    return df\n",
    "\n",
    "def normalization(df):\n",
    "    def minmax(group,name):\n",
    "        scaler = MinMaxScaler()\n",
    "        return pd.DataFrame(data=scaler.fit_transform(group),columns=group.columns,index=data_edit.loc[data_edit['testClassName'] == name, group.columns].index)\n",
    "    \n",
    "    groups = df.drop(labels=['testMethodName','potentialTargetQualifiedName','AAA'], axis=1).groupby('testClassName')\n",
    "    df_copy = df.copy()\n",
    "    for name, group in groups:\n",
    "        group = group.drop(labels=['testClassName'], axis=1)\n",
    "        group_minmax = minmax(group,name)\n",
    "        df_copy.loc[df_copy['testClassName'] == name, group.columns] = group_minmax\n",
    "    return df_copy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>testClassName</th>\n",
       "      <th>testMethodName</th>\n",
       "      <th>potentialTargetQualifiedName</th>\n",
       "      <th>AAA</th>\n",
       "      <th>Assert Distance</th>\n",
       "      <th>Name Similarity</th>\n",
       "      <th>Tag-Mock</th>\n",
       "      <th>Tag-New</th>\n",
       "      <th>Tag-Test</th>\n",
       "      <th>Tag-Get</th>\n",
       "      <th>Tag-Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IterConfigUtilTest</td>\n",
       "      <td>test5</td>\n",
       "      <td>NEW org.apache.accumulo.core.conf.Configuratio...</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IterConfigUtilTest</td>\n",
       "      <td>test5</td>\n",
       "      <td>org.apache.accumulo.core.conf.ConfigurationCop...</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IterConfigUtilTest</td>\n",
       "      <td>test5</td>\n",
       "      <td>org.apache.accumulo.core.conf.ConfigurationCop...</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IterConfigUtilTest</td>\n",
       "      <td>test5</td>\n",
       "      <td>org.apache.accumulo.core.conf.ConfigurationCop...</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IterConfigUtilTest</td>\n",
       "      <td>test5</td>\n",
       "      <td>NEW org.apache.hadoop.io.Text(S...</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19347</th>\n",
       "      <td>ConsulDynamicConfigurationTest</td>\n",
       "      <td>testGetConfig</td>\n",
       "      <td>ASSERT org.junit.jupiter.api.Assertions.assert...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19348</th>\n",
       "      <td>ConsulDynamicConfigurationTest</td>\n",
       "      <td>testGetConfig</td>\n",
       "      <td>org.apache.dubbo.common.config.configcenter.Dy...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19349</th>\n",
       "      <td>ConsulDynamicConfigurationTest</td>\n",
       "      <td>testGetConfig</td>\n",
       "      <td>ASSERT org.junit.jupiter.api.Assertions.assert...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19350</th>\n",
       "      <td>ConsulDynamicConfigurationTest</td>\n",
       "      <td>testGetConfig</td>\n",
       "      <td>org.apache.dubbo.common.config.configcenter.Dy...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19351</th>\n",
       "      <td>ConsulDynamicConfigurationTest</td>\n",
       "      <td>testGetConfig</td>\n",
       "      <td>ASSERT org.junit.jupiter.api.Assertions.assert...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19352 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        testClassName testMethodName  \\\n",
       "0                  IterConfigUtilTest          test5   \n",
       "1                  IterConfigUtilTest          test5   \n",
       "2                  IterConfigUtilTest          test5   \n",
       "3                  IterConfigUtilTest          test5   \n",
       "4                  IterConfigUtilTest          test5   \n",
       "...                               ...            ...   \n",
       "19347  ConsulDynamicConfigurationTest  testGetConfig   \n",
       "19348  ConsulDynamicConfigurationTest  testGetConfig   \n",
       "19349  ConsulDynamicConfigurationTest  testGetConfig   \n",
       "19350  ConsulDynamicConfigurationTest  testGetConfig   \n",
       "19351  ConsulDynamicConfigurationTest  testGetConfig   \n",
       "\n",
       "                            potentialTargetQualifiedName  AAA  \\\n",
       "0      NEW org.apache.accumulo.core.conf.Configuratio...    0   \n",
       "1      org.apache.accumulo.core.conf.ConfigurationCop...    0   \n",
       "2      org.apache.accumulo.core.conf.ConfigurationCop...    0   \n",
       "3      org.apache.accumulo.core.conf.ConfigurationCop...    0   \n",
       "4                     NEW org.apache.hadoop.io.Text(S...    0   \n",
       "...                                                  ...  ...   \n",
       "19347  ASSERT org.junit.jupiter.api.Assertions.assert...    2   \n",
       "19348  org.apache.dubbo.common.config.configcenter.Dy...    1   \n",
       "19349  ASSERT org.junit.jupiter.api.Assertions.assert...    2   \n",
       "19350  org.apache.dubbo.common.config.configcenter.Dy...    1   \n",
       "19351  ASSERT org.junit.jupiter.api.Assertions.assert...    2   \n",
       "\n",
       "       Assert Distance  Name Similarity  Tag-Mock  Tag-New  Tag-Test  Tag-Get  \\\n",
       "0                 18.0              5.0         0        1         0        0   \n",
       "1                 17.0              5.0         0        0         0        0   \n",
       "2                 16.0              5.0         0        0         0        0   \n",
       "3                 15.0              5.0         0        0         0        0   \n",
       "4                 14.0              5.0         0        1         0        0   \n",
       "...                ...              ...       ...      ...       ...      ...   \n",
       "19347              0.0              6.0         0        0         0        0   \n",
       "19348              1.0              4.0         0        0         0        1   \n",
       "19349              0.0              6.0         0        0         0        0   \n",
       "19350              1.0              4.0         0        0         0        1   \n",
       "19351              0.0              6.0         0        0         0        0   \n",
       "\n",
       "       Tag-Set  \n",
       "0            0  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            0  \n",
       "...        ...  \n",
       "19347        0  \n",
       "19348        0  \n",
       "19349        0  \n",
       "19350        0  \n",
       "19351        0  \n",
       "\n",
       "[19352 rows x 11 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix the multi tagging problem\n",
    "data_edit = Data_twist(data_edit)\n",
    "# normalization in each cases\n",
    "# data_edit = normalization(data_edit)\n",
    "data_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=12388 (64.014%)\n",
      "Class=1, n=1024 (5.291%)\n",
      "Class=2, n=5940 (30.695%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "y = np.array(data_edit.AAA)\n",
    "\n",
    "X = np.array(data_edit.drop(labels=['testClassName','testMethodName','potentialTargetQualifiedName','AAA'], axis=1))\n",
    "\n",
    "counter = Counter(y)\n",
    "for k,v in counter.items():\n",
    "\tper = v / len(y) * 100\n",
    "\tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "plt.bar(counter.keys(), counter.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=100)\n",
    "\n",
    "dtrain = xgb.DMatrix(data=x_train,label=y_train)\n",
    "dtest = xgb.DMatrix(data=x_test,label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth':5, 'eta':0.5, 'verbosity':1, 'objective':'multi:softprob', 'num_class':3}\n",
    "param['nthread'] = 4\n",
    "param['seed'] = 100\n",
    "# param['eval_metric'] = 'auc'\n",
    "# param['eval_metric'] = ['auc', 'ams@0']\n",
    "# param['eval_metric'] = ['rmse']\n",
    "# evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "num_round = 100\n",
    "bst_without_evallist = xgb.train(param, dtrain, num_round)\n",
    "# num_round = 10\n",
    "# bst_with_evallist = xgb.train(param, dtrain, num_round, evallist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 0 ... 0 2 2]\n",
      "1936\n",
      "[0 2 0 ... 0 2 2]\n",
      "1936\n",
      "Action Accuracy: 0.205607476635514\n",
      "Assert accuracy: 0.7166947723440135\n",
      "accuracy : 0.8217975206611571\n",
      "Arrange Recall: 0.8188976377952756\n",
      "action recall: 0.07801418439716312\n",
      "Assert recall: 0.7059800664451827\n",
      "Arrange per: 0.9255663430420712\n",
      "action per: 0.205607476635514\n",
      "Assert per: 0.7166947723440135\n"
     ]
    }
   ],
   "source": [
    "ans = bst_without_evallist.predict(dtest)\n",
    "prob = np.argmax(ans, axis=1)\n",
    "print(prob)\n",
    "print(len(prob))\n",
    "print(y_test)\n",
    "print(len(y_test))\n",
    "def acc(prob, y_test):\n",
    "    count = 0\n",
    "    target_count = 0\n",
    "    target_acc_count = 0\n",
    "    assert_count = 0\n",
    "    assert_acc_count = 0\n",
    "    for _ in range(len(prob)):\n",
    "        if prob[_] == y_test[_]:\n",
    "            count += 1\n",
    "        if prob[_] == y_test[_] and prob[_] == 1:\n",
    "            target_acc_count += 1\n",
    "        if y_test[_] == 1:\n",
    "            target_count +=1\n",
    "        if prob[_] == y_test[_] and prob[_] == 2:\n",
    "            assert_acc_count +=1\n",
    "        if y_test[_] == 2:\n",
    "            assert_count +=1\n",
    "    acc = count/len(y_test)\n",
    "    try:\n",
    "        action_acc = target_acc_count/target_count\n",
    "        print(\"Action Accuracy: {num}\".format(num=action_acc))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    # print(assert_count)\n",
    "    # print(assert_acc_count)\n",
    "    try:\n",
    "        assert_acc = assert_acc_count/assert_count\n",
    "        print(\"Assert accuracy: {num}\".format(num=assert_acc))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    print(\"accuracy : {num}\".format(num=acc)) \n",
    "def recall(predict, target):\n",
    "    \n",
    "    arrange_TP = 0\n",
    "    arrange_FN = 0\n",
    "    action_TP = 0\n",
    "    action_FN = 0\n",
    "    assert_TP = 0\n",
    "    assert_FN = 0\n",
    "\n",
    "    for _ in range(len(predict)):\n",
    "\n",
    "        if predict[_] == target[_] and predict[_] == 0:\n",
    "            arrange_TP += 1\n",
    "        if predict[_] != target[_] and target[_] != 0:\n",
    "            arrange_FN +=1\n",
    "        if predict[_] == target[_] and predict[_] == 1:\n",
    "            action_TP += 1\n",
    "        if predict[_] != target[_] and target[_] != 1:\n",
    "            action_FN +=1\n",
    "        if predict[_] == target[_] and predict[_] == 2:\n",
    "            assert_TP += 1\n",
    "        if predict[_] != target[_] and target[_] != 2:\n",
    "            assert_FN +=1\n",
    "\n",
    "    try:\n",
    "        arrange_recall = arrange_TP/(arrange_TP+arrange_FN)\n",
    "        print(\"Arrange Recall: {num}\".format(num=arrange_recall))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    # print(assert_count)\n",
    "    # print(assert_acc_count)\n",
    "    try:\n",
    "        action_recall = action_TP/(action_TP+action_FN)\n",
    "        print(\"action recall: {num}\".format(num=action_recall))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    try:\n",
    "        assert_recall = assert_TP/(assert_TP+assert_FN)\n",
    "        print(\"Assert recall: {num}\".format(num=assert_recall))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "def percision(predict, target):\n",
    "    \n",
    "    arrange_TP = 0\n",
    "    arrange_FP = 0\n",
    "    action_TP = 0\n",
    "    action_FP = 0\n",
    "    assert_TP = 0\n",
    "    assert_FP = 0\n",
    "\n",
    "    for _ in range(len(predict)):\n",
    "\n",
    "        if predict[_] == target[_] and predict[_] == 0:\n",
    "            arrange_TP += 1\n",
    "        if predict[_] != target[_] and target[_] == 0:\n",
    "            arrange_FP +=1\n",
    "        if predict[_] == target[_] and predict[_] == 1:\n",
    "            action_TP += 1\n",
    "        if predict[_] != target[_] and target[_] == 1:\n",
    "            action_FP +=1\n",
    "        if predict[_] == target[_] and predict[_] == 2:\n",
    "            assert_TP += 1\n",
    "        if predict[_] != target[_] and target[_] == 2:\n",
    "            assert_FP +=1\n",
    "\n",
    "    try:\n",
    "        arrange_per = arrange_TP/(arrange_TP+arrange_FP)\n",
    "        print(\"Arrange per: {num}\".format(num=arrange_per))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    # print(assert_count)\n",
    "    # print(assert_acc_count)\n",
    "    try:\n",
    "        action_per = action_TP/(action_TP+action_FP)\n",
    "        print(\"action per: {num}\".format(num=action_per))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    try:\n",
    "        assert_per = assert_TP/(assert_TP+assert_FP)\n",
    "        print(\"Assert per: {num}\".format(num=assert_per))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "acc(prob,y_test)\n",
    "recall(prob,y_test)\n",
    "percision(prob,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banlanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=12388 (33.333%)\n",
      "Class=1, n=12388 (33.333%)\n",
      "Class=2, n=12388 (33.333%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# label encode the target variable\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "# transform the dataset\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)\n",
    "# summarize distribution\n",
    "counter = Counter(y)\n",
    "for k,v in counter.items():\n",
    "\tper = v / len(y) * 100\n",
    "\tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 0 2 1]\n",
      "3717\n",
      "[0 1 2 ... 0 2 1]\n",
      "3717\n",
      "Action Accuracy: 0.9295659295659295\n",
      "Assert accuracy: 0.7097032878909383\n",
      "accuracy : 0.8194780737153619\n",
      "Arrange Recall: 0.6960651289009498\n",
      "action recall: 0.6598837209302325\n",
      "Assert recall: 0.7412060301507538\n",
      "Arrange per: 0.8214571657325861\n",
      "action per: 0.9295659295659295\n",
      "Assert per: 0.7097032878909383\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=100)\n",
    "\n",
    "dtrain = xgb.DMatrix(data=x_train,label=y_train)\n",
    "dtest = xgb.DMatrix(data=x_test,label=y_test)\n",
    "\n",
    "param = {'max_depth':5, 'eta':0.5, 'verbosity':1, 'objective':'multi:softprob', 'num_class':3}\n",
    "param['nthread'] = 4\n",
    "param['seed'] = 100\n",
    "num_round = 100\n",
    "bst_without_evallist = xgb.train(param, dtrain, num_round)\n",
    "ans = bst_without_evallist.predict(dtest)\n",
    "prob = np.argmax(ans, axis=1)\n",
    "print(prob)\n",
    "print(len(prob))\n",
    "print(y_test)\n",
    "print(len(y_test))\n",
    "acc(prob,y_test)\n",
    "recall(prob,y_test)\n",
    "percision(prob,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_kf(prob, y_test):\n",
    "    count = 0\n",
    "    target_count = 0\n",
    "    target_acc_count = 0\n",
    "    assert_count = 0\n",
    "    assert_acc_count = 0\n",
    "    for _ in range(len(prob)):\n",
    "        if prob[_] == y_test[_]:\n",
    "            count += 1\n",
    "        if prob[_] == y_test[_] and prob[_] == 1:\n",
    "            target_acc_count += 1\n",
    "        if y_test[_] == 1:\n",
    "            target_count +=1\n",
    "        if prob[_] == y_test[_] and prob[_] == 2:\n",
    "            assert_acc_count +=1\n",
    "        if y_test[_] == 2:\n",
    "            assert_count +=1\n",
    "    acc = count/len(y_test)\n",
    "    try:\n",
    "        action_acc = target_acc_count/target_count\n",
    "        print(\"Action Accuracy: {num}\".format(num=action_acc))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    # print(assert_count)\n",
    "    # print(assert_acc_count)\n",
    "    try:\n",
    "        assert_acc = assert_acc_count/assert_count\n",
    "        print(\"Assert accuracy: {num}\".format(num=assert_acc))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    print(\"accuracy : {num}\".format(num=acc)) \n",
    "    \n",
    "def recall_kf(predict, target):\n",
    "    \n",
    "    arrange_TP = 0\n",
    "    arrange_FN = 0\n",
    "    action_TP = 0\n",
    "    action_FN = 0\n",
    "    assert_TP = 0\n",
    "    assert_FN = 0\n",
    "\n",
    "    for _ in range(len(predict)):\n",
    "\n",
    "        if predict[_] == target[_] and predict[_] == 0:\n",
    "            arrange_TP += 1\n",
    "        if predict[_] != target[_] and target[_] != 0:\n",
    "            arrange_FN +=1\n",
    "        if predict[_] == target[_] and predict[_] == 1:\n",
    "            action_TP += 1\n",
    "        if predict[_] != target[_] and target[_] != 1:\n",
    "            action_FN +=1\n",
    "        if predict[_] == target[_] and predict[_] == 2:\n",
    "            assert_TP += 1\n",
    "        if predict[_] != target[_] and target[_] != 2:\n",
    "            assert_FN +=1\n",
    "\n",
    "    try:\n",
    "        arrange_recall = arrange_TP/(arrange_TP+arrange_FN)\n",
    "        # print(\"Arrange Recall: {num}\".format(num=arrange_recall))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    # print(assert_count)\n",
    "    # print(assert_acc_count)\n",
    "    try:\n",
    "        action_recall = action_TP/(action_TP+action_FN)\n",
    "        # print(\"action recall: {num}\".format(num=action_recall))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    try:\n",
    "        assert_recall = assert_TP/(assert_TP+assert_FN)\n",
    "        # print(\"Assert recall: {num}\".format(num=assert_recall))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return (arrange_recall,action_recall,assert_recall)\n",
    "\n",
    "def percision_kf(predict, target):\n",
    "    \n",
    "    arrange_TP = 0\n",
    "    arrange_FP = 0\n",
    "    action_TP = 0\n",
    "    action_FP = 0\n",
    "    assert_TP = 0\n",
    "    assert_FP = 0\n",
    "\n",
    "    for _ in range(len(predict)):\n",
    "\n",
    "        if predict[_] == target[_] and predict[_] == 0:\n",
    "            arrange_TP += 1\n",
    "        if predict[_] != target[_] and target[_] == 0:\n",
    "            arrange_FP +=1\n",
    "        if predict[_] == target[_] and predict[_] == 1:\n",
    "            action_TP += 1\n",
    "        if predict[_] != target[_] and target[_] == 1:\n",
    "            action_FP +=1\n",
    "        if predict[_] == target[_] and predict[_] == 2:\n",
    "            assert_TP += 1\n",
    "        if predict[_] != target[_] and target[_] == 2:\n",
    "            assert_FP +=1\n",
    "\n",
    "    try:\n",
    "        arrange_per = arrange_TP/(arrange_TP+arrange_FP)\n",
    "        # print(\"Arrange per: {num}\".format(num=arrange_per))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    # print(assert_count)\n",
    "    # print(assert_acc_count)\n",
    "    try:\n",
    "        action_per = action_TP/(action_TP+action_FP)\n",
    "        # print(\"action per: {num}\".format(num=action_per))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    try:\n",
    "        assert_per = assert_TP/(assert_TP+assert_FP)\n",
    "        # print(\"Assert per: {num}\".format(num=assert_per))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return (arrange_per,action_per,assert_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10,shuffle=True)\n",
    "\n",
    "# 归一化\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_edit_minmax = pd.DataFrame(data=scaler.fit_transform(X))\n",
    "target_df = pd.DataFrame(data=y)\n",
    "# data_edit_minmax = pd.DataFrame(data=X)\n",
    "# target_df = pd.DataFrame(data=y)\n",
    "# target_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Round 2\n",
      "Round 3\n",
      "Round 4\n",
      "Round 5\n",
      "Round 6\n",
      "Round 7\n",
      "Round 8\n",
      "Round 9\n",
      "Round 10\n"
     ]
    }
   ],
   "source": [
    "# XGB\n",
    "ar_recall_list = []\n",
    "ar_precision_list =[]\n",
    "ac_recall_list = []\n",
    "ac_precision_list =[]\n",
    "as_recall_list = []\n",
    "as_precision_list =[]\n",
    "rounds = 0\n",
    "for i in range(10):\n",
    "    rounds += 1\n",
    "    for train_index, test_index in kf.split(data_edit_minmax):\n",
    "        x_train, x_test = data_edit_minmax.iloc[train_index],data_edit_minmax.iloc[test_index]\n",
    "        y_train, y_test = target_df.iloc[train_index],target_df.iloc[test_index]\n",
    "    \n",
    "        dtrain = xgb.DMatrix(data=x_train,label=y_train)\n",
    "        dtest = xgb.DMatrix(data=x_test,label=y_test)\n",
    "\n",
    "        param = {'max_depth':5, 'eta':0.5, 'verbosity':1, 'objective':'multi:softprob', 'num_class':3}\n",
    "        param['nthread'] = 4\n",
    "        param['seed'] = 100\n",
    "        num_round = 100\n",
    "        bst_without_evallist = xgb.train(param, dtrain, num_round)\n",
    "        ans = bst_without_evallist.predict(dtest)\n",
    "        prob = np.argmax(ans, axis=1)\n",
    "      \n",
    "        arrange_recall,action_recall,assert_recall =recall_kf(prob,y_test.values)\n",
    "        arrange_pre,action_pre,assert_pre = percision_kf(prob,y_test.values)\n",
    "        ar_recall_list.append(arrange_recall)\n",
    "        ar_precision_list.append(arrange_pre)\n",
    "        ac_recall_list.append(action_recall)\n",
    "        ac_precision_list.append(action_pre)\n",
    "        as_recall_list.append(assert_recall)\n",
    "        as_precision_list.append(assert_pre)\n",
    "    print('Round {0}'.format(rounds))\n",
    "dic = {'arrange_recall':ar_recall_list,'arrange_precision':ar_precision_list,'action_recall':ac_recall_list,'action_precision':ac_precision_list,'assert_recall':as_recall_list,'assert_precision':as_precision_list}\n",
    "xgb_result_df = pd.core.frame.DataFrame(dic)\n",
    "xgb_result_df.to_csv('./RQ1/xgb_result.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Round 2\n",
      "Round 3\n",
      "Round 4\n",
      "Round 5\n",
      "Round 6\n",
      "Round 7\n",
      "Round 8\n",
      "Round 9\n",
      "Round 10\n"
     ]
    }
   ],
   "source": [
    "# RF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "ar_recall_list = []\n",
    "ar_precision_list =[]\n",
    "ac_recall_list = []\n",
    "ac_precision_list =[]\n",
    "as_recall_list = []\n",
    "as_precision_list =[]\n",
    "rounds = 0\n",
    "for i in range(10):\n",
    "    rounds += 1\n",
    "    for train_index, test_index in kf.split(data_edit_minmax):\n",
    "        x_train, x_test = data_edit_minmax.iloc[train_index],data_edit_minmax.iloc[test_index]\n",
    "        y_train, y_test = target_df.iloc[train_index],target_df.iloc[test_index]\n",
    "    \n",
    "        rf = RandomForestClassifier(oob_score=True)\n",
    "        rf.fit(x_train, y_train.values.ravel())\n",
    "        rf_pred = rf.predict(x_test)\n",
    "   \n",
    "        prob = rf_pred\n",
    "\n",
    "        arrange_recall,action_recall,assert_recall =recall_kf(prob,y_test.values)\n",
    "        arrange_pre,action_pre,assert_pre = percision_kf(prob,y_test.values)\n",
    "        ar_recall_list.append(arrange_recall)\n",
    "        ar_precision_list.append(arrange_pre)\n",
    "        ac_recall_list.append(action_recall)\n",
    "        ac_precision_list.append(action_pre)\n",
    "        as_recall_list.append(assert_recall)\n",
    "        as_precision_list.append(assert_pre)\n",
    "    print('Round {0}'.format(rounds))\n",
    "dic = {'arrange_recall':ar_recall_list,'arrange_precision':ar_precision_list,'action_recall':ac_recall_list,'action_precision':ac_precision_list,'assert_recall':as_recall_list,'assert_precision':as_precision_list}\n",
    "rf_result_df = pd.core.frame.DataFrame(dic)\n",
    "rf_result_df.to_csv('./RQ1/rf_result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Round 2\n",
      "Round 3\n",
      "Round 4\n",
      "Round 5\n",
      "Round 6\n",
      "Round 7\n",
      "Round 8\n",
      "Round 9\n",
      "Round 10\n"
     ]
    }
   ],
   "source": [
    "# DT\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ar_recall_list = []\n",
    "ar_precision_list =[]\n",
    "ac_recall_list = []\n",
    "ac_precision_list =[]\n",
    "as_recall_list = []\n",
    "as_precision_list =[]\n",
    "rounds = 0\n",
    "for i in range(10):\n",
    "    rounds += 1\n",
    "    for train_index, test_index in kf.split(data_edit_minmax):\n",
    "        x_train, x_test = data_edit_minmax.iloc[train_index],data_edit_minmax.iloc[test_index]\n",
    "        y_train, y_test = target_df.iloc[train_index],target_df.iloc[test_index]\n",
    "    \n",
    "        dt = DecisionTreeClassifier()\n",
    "        dt.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "        prob = dt.predict(x_test)  \n",
    "        \n",
    "        arrange_recall,action_recall,assert_recall =recall_kf(prob,y_test.values)\n",
    "        arrange_pre,action_pre,assert_pre = percision_kf(prob,y_test.values)\n",
    "        ar_recall_list.append(arrange_recall)\n",
    "        ar_precision_list.append(arrange_pre)\n",
    "        ac_recall_list.append(action_recall)\n",
    "        ac_precision_list.append(action_pre)\n",
    "        as_recall_list.append(assert_recall)\n",
    "        as_precision_list.append(assert_pre)\n",
    "    print('Round {0}'.format(rounds))\n",
    "dic = {'arrange_recall':ar_recall_list,'arrange_precision':ar_precision_list,'action_recall':ac_recall_list,'action_precision':ac_precision_list,'assert_recall':as_recall_list,'assert_precision':as_precision_list}\n",
    "dt_result_df = pd.core.frame.DataFrame(dic)\n",
    "dt_result_df.to_csv('./RQ1/dt_result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Round 2\n",
      "Round 3\n",
      "Round 4\n",
      "Round 5\n",
      "Round 6\n",
      "Round 7\n",
      "Round 8\n",
      "Round 9\n",
      "Round 10\n"
     ]
    }
   ],
   "source": [
    "# SVM oneVSone\n",
    "# A=B=C=D=0; # 票数初始化\n",
    "# (A，B)-classifier 如果是A win，则A=A+1;otherwise, B=B+1;\n",
    "# (A，C)-classifier 如果是A win，则A=A+1;otherwise, C=C+1;\n",
    "# …\n",
    "# (C，D)-classifier 如果是A win，则C=C+1;otherwise, D=D+1;\n",
    "# The decision is the Max(A，B，C，D)\n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import SVC\n",
    "ar_recall_list = []\n",
    "ar_precision_list =[]\n",
    "ac_recall_list = []\n",
    "ac_precision_list =[]\n",
    "as_recall_list = []\n",
    "as_precision_list =[]\n",
    "rounds = 0\n",
    "for i in range(10):\n",
    "    rounds += 1\n",
    "    for train_index, test_index in kf.split(data_edit_minmax):\n",
    "        x_train, x_test = data_edit_minmax.iloc[train_index],data_edit_minmax.iloc[test_index]\n",
    "        y_train, y_test = target_df.iloc[train_index],target_df.iloc[test_index]\n",
    "    \n",
    "        nb = OneVsOneClassifier(SVC())\n",
    "        nb.fit(x_train,y_train.values.ravel())\n",
    "        prob = nb.predict(x_test)  \n",
    "\n",
    "        arrange_recall,action_recall,assert_recall =recall_kf(prob,y_test.values)\n",
    "        arrange_pre,action_pre,assert_pre = percision_kf(prob,y_test.values)\n",
    "        ar_recall_list.append(arrange_recall)\n",
    "        ar_precision_list.append(arrange_pre)\n",
    "        ac_recall_list.append(action_recall)\n",
    "        ac_precision_list.append(action_pre)\n",
    "        as_recall_list.append(assert_recall)\n",
    "        as_precision_list.append(assert_pre)\n",
    "    print('Round {0}'.format(rounds))\n",
    "dic = {'arrange_recall':ar_recall_list,'arrange_precision':ar_precision_list,'action_recall':ac_recall_list,'action_precision':ac_precision_list,'assert_recall':as_recall_list,'assert_precision':as_precision_list}\n",
    "nb_result_df = pd.core.frame.DataFrame(dic)\n",
    "nb_result_df.to_csv('./RQ1/svm_result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Round 2\n",
      "Round 3\n",
      "Round 4\n",
      "Round 5\n",
      "Round 6\n",
      "Round 7\n",
      "Round 8\n",
      "Round 9\n",
      "Round 10\n"
     ]
    }
   ],
   "source": [
    "# LR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "ar_recall_list = []\n",
    "ar_precision_list =[]\n",
    "ac_recall_list = []\n",
    "ac_precision_list =[]\n",
    "as_recall_list = []\n",
    "as_precision_list =[]\n",
    "rounds = 0\n",
    "for i in range(10):\n",
    "    rounds += 1\n",
    "    for train_index, test_index in kf.split(data_edit_minmax):\n",
    "        x_train, x_test = data_edit_minmax.iloc[train_index],data_edit_minmax.iloc[test_index]\n",
    "        y_train, y_test = target_df.iloc[train_index],target_df.iloc[test_index]\n",
    "    \n",
    "        lr = LogisticRegression(penalty='l2',solver='newton-cg',multi_class='multinomial')\n",
    "        lr.fit(x_train, y_train.values.ravel())\n",
    "        lr_pred = lr.predict(x_test)\n",
    "        # print(rf_pred)\n",
    "        prob = lr_pred\n",
    "        \n",
    "        arrange_recall,action_recall,assert_recall =recall_kf(prob,y_test.values)\n",
    "        arrange_pre,action_pre,assert_pre = percision_kf(prob,y_test.values)\n",
    "        ar_recall_list.append(arrange_recall)\n",
    "        ar_precision_list.append(arrange_pre)\n",
    "        ac_recall_list.append(action_recall)\n",
    "        ac_precision_list.append(action_pre)\n",
    "        as_recall_list.append(assert_recall)\n",
    "        as_precision_list.append(assert_pre)\n",
    "    print('Round {0}'.format(rounds))\n",
    "dic = {'arrange_recall':ar_recall_list,'arrange_precision':ar_precision_list,'action_recall':ac_recall_list,'action_precision':ac_precision_list,'assert_recall':as_recall_list,'assert_precision':as_precision_list}\n",
    "lr_result_df = pd.core.frame.DataFrame(dic)\n",
    "lr_result_df.to_csv('./RQ1/lr_result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 2\n",
      "Round 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/chenhao/Documents/Code/Python/Venv/jpt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 9\n",
      "Round 10\n"
     ]
    }
   ],
   "source": [
    "# BPNN\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "ar_recall_list = []\n",
    "ar_precision_list =[]\n",
    "ac_recall_list = []\n",
    "ac_precision_list =[]\n",
    "as_recall_list = []\n",
    "as_precision_list =[]\n",
    "rounds = 0\n",
    "for i in range(10):\n",
    "    rounds += 1\n",
    "    for train_index, test_index in kf.split(data_edit_minmax):\n",
    "        x_train, x_test = data_edit_minmax.iloc[train_index],data_edit_minmax.iloc[test_index]\n",
    "        y_train, y_test = target_df.iloc[train_index],target_df.iloc[test_index]\n",
    "    \n",
    "        bpnn = MLPClassifier(solver='adam',alpha=1e-5,hidden_layer_sizes=(7,7,14),activation='relu',max_iter=400)\n",
    "        bpnn.fit(x_train, y_train.values.ravel())\n",
    "        bpnn_pred = bpnn.predict(x_test)\n",
    "        # print(rf_pred)\n",
    "        prob = bpnn_pred\n",
    "        \n",
    "        arrange_recall,action_recall,assert_recall =recall_kf(prob,y_test.values)\n",
    "        arrange_pre,action_pre,assert_pre = percision_kf(prob,y_test.values)\n",
    "        ar_recall_list.append(arrange_recall)\n",
    "        ar_precision_list.append(arrange_pre)\n",
    "        ac_recall_list.append(action_recall)\n",
    "        ac_precision_list.append(action_pre)\n",
    "        as_recall_list.append(assert_recall)\n",
    "        as_precision_list.append(assert_pre)\n",
    "    print('Round {0}'.format(rounds))\n",
    "dic = {'arrange_recall':ar_recall_list,'arrange_precision':ar_precision_list,'action_recall':ac_recall_list,'action_precision':ac_precision_list,'assert_recall':as_recall_list,'assert_precision':as_precision_list}\n",
    "bpnn_result_df = pd.core.frame.DataFrame(dic)\n",
    "bpnn_result_df.to_csv('./RQ1/bpnn_result.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./RQ1/lr_result.csv\n",
      "./RQ1/svm_result.csv\n",
      "./RQ1/dt_result.csv\n",
      "./RQ1/bpnn_result.csv\n",
      "./RQ1/rf_result.csv\n",
      "./RQ1/xgb_result.csv\n"
     ]
    }
   ],
   "source": [
    "## F1 and Avarage and Ttest\n",
    "### f1 = 2*(precision*recall)/(precision+recall)\n",
    "from scipy import stats\n",
    "import os\n",
    "\n",
    "def gen_p(data1,data2):\n",
    "    '''data should be numpy array'''\n",
    "    equal_var = True\n",
    "    if stats.levene(data1,data2)[1] < 0.05:\n",
    "        equal_var = False\n",
    "    return stats.ttest_ind(data1,data2,equal_var)[1]\n",
    "\n",
    "def gen_f1(p,r):\n",
    "    return 2*(p*r)/(p+r)\n",
    "\n",
    "def findAllFile(folder_path):\n",
    "    for root, ds, fs in os.walk(folder_path):\n",
    "        for f in fs:\n",
    "            fullname = os.path.join(root, f)\n",
    "            yield fullname\n",
    "########## File list ##############\n",
    "all_test_file_list = []\n",
    "all_feature_file_list = []\n",
    "\n",
    "for i in findAllFile('./RQ1/'):\n",
    "    if i == './RQ1/.DS_Store': #TODO: need fix\n",
    "        continue\n",
    "    else:\n",
    "        all_test_file_list.append(i)\n",
    "        print(i)\n",
    "\n",
    "################### F1 genaration fot all the t-test files ############\n",
    "for file in all_test_file_list:\n",
    "    processing_df = pd.read_csv(file)\n",
    "    processing_df.insert(2,'arrange_f1',0)\n",
    "    processing_df.insert(5,'action_f1',0)\n",
    "    processing_df.insert(8,'assert_f1',0)\n",
    "\n",
    "    for _ in range(100):\n",
    "        try:\n",
    "            processing_df.loc[_,'arrange_f1'] = gen_f1(processing_df['arrange_precision'][_],processing_df['arrange_recall'][_])\n",
    "            processing_df.loc[_,'action_f1'] = gen_f1(processing_df['action_precision'][_],processing_df['action_recall'][_])\n",
    "            processing_df.loc[_,'assert_f1'] = gen_f1(processing_df['assert_precision'][_],processing_df['assert_recall'][_])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print()\n",
    "    \n",
    "    name = './f1/RQ1/'+file.split('/')[-1]\n",
    "    processing_df.to_csv(name,index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e3fe87781377a767eb7072c3979a56ac33d74b52f6024e29ea4abfd91450d9a4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('jpt': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
